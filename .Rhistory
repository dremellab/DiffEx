rpkm_counts <- sweep(merged_counts[, expr_cols], 1, merged_counts$gene_length_kb, "/")  # divide by gene length
rpkm_counts <- sweep(rpkm_counts, 2, library_sizes / 1e6, "/")  # divide by library size (in millions)
# Log2-transform RPKM
log2_rpkm_counts <- log2(rpkm_counts)
# Subset ERCC rows
ercc_rows <- grepl("^ERCC", rownames(log2_rpkm_counts))
log2_ercc_counts <- log2_rpkm_counts[ercc_rows, ]
# Remove -Inf and NA
log2_ercc_counts <- log2_ercc_counts[!apply(log2_ercc_counts, 1, function(x) any(is.na(x) | is.infinite(x))), ]
# Clean up rownames: keep only the first part before the '|'
rownames(log2_ercc_counts) <- sub("\\|.*", "", rownames(log2_ercc_counts))
common_erccs <- intersect(rownames(log2_ercc_counts), rownames(ercc_conc))
counts_matched <- log2_ercc_counts[common_erccs, ]
# reorder ercc_conc to match counts_matched
ercc_conc <- ercc_conc[common_erccs, ]
# Initialize results data frame
ercc_qc <- data.frame(
Sample = colnames(counts_matched),
Slope = NA_real_,
Intercept = NA_real_,
Rsquared = NA_real_
)
# Fit linear model per sample
for (s in colnames(counts_matched)) {
y <- counts_matched[,s] # already log2 transformed RPKM values
x <- ercc_conc$log2molecules
fit <- lm(y ~ x)
ercc_qc[ercc_qc$Sample == s, "Slope"]     <- coef(fit)[2]
ercc_qc[ercc_qc$Sample == s, "Intercept"] <- coef(fit)[1]
ercc_qc[ercc_qc$Sample == s, "Rsquared"]  <- summary(fit)$r.squared
}
# Create summary table
ercc_norm_df <- data.frame(
Sample = ercc_qc$Sample,
Slope = format(ercc_qc$Slope, digits = 3),
Intercept = format(ercc_qc$Intercept, digits = 3),
Rsquared = format(ercc_qc$Rsquared, digits = 3)
)
# Implement corrected log2RPKM = (log2RPKM - intercept) / slope (per sample)
pseudo_log2_normalized_counts <- log2_rpkm_counts
for (s in colnames(pseudo_log2_normalized_counts)) {
intercept <- ercc_qc$Intercept[ercc_qc$Sample == s]
slope <- ercc_qc$Slope[ercc_qc$Sample == s]
# Sanity check
if (length(intercept) != 1 || length(slope) != 1) {
stop(glue::glue("❌ Could not uniquely match slope/intercept for sample {s}."))
}
# Apply transformation
pseudo_log2_normalized_counts[, s] <- (pseudo_log2_normalized_counts[, s] - intercept) / slope
}
pseudo_log2_normalized_counts[pseudo_log2_normalized_counts == -Inf] <- NA
}
# pseudo_log2_normalized_counts_df <- as.data.frame(pseudo_log2_normalized_counts) %>%
#   rownames_to_column(var = "gene_id")
#
# write.table(pseudo_log2_normalized_counts_df,
#             file = file.path(output_base, "ERCC_pseudo_log2normalized_counts.tsv"),
#             sep = "\t",
#             quote = FALSE,
#             col.names = TRUE,
#             row.names = FALSE)
#| code-fold: true
#| code-summary: "📊 ERCC Summary Table"
#| message: true
#| warning: false
#| echo: false
if (isTRUE(params$useERCC)) {
DT::datatable(
ercc_norm_df,
caption = "📊 ERCC-Based Library Sizes and Intercept/Slope/R-squared",
rownames = FALSE,
options = list(pageLength = 20, autoWidth = TRUE)
)
}
#| code-fold: true
#| code-summary: "🔧 Functions"
#| message: true
#| warning: false
#| echo: false
# Adds a gene_id column from rownames if not already present:
add_gene_id_column_if_missing <- function(df) {
if (!"gene_id" %in% colnames(df)) {
df$gene_id <- rownames(df)
}
return(df)
}
# Moves the gene_id column to rownames if it exists:
set_gene_id_as_rownames_if_exists <- function(df) {
if ("gene_id" %in% colnames(df)) {
rownames(df) <- df$gene_id
df$gene_id <- NULL
}
return(df)
}
log2FC_threshold <- params$log2FC_threshold
pvalue_threshold <- params$pvalue_threshold
fdr_threshold <- params$fdr_threshold
make_violin_plot <- function(normalized_counts,
xlab = "Sample",
ylab = "Normalized Counts",
title = "Violin Plot of Normalized Counts by Sample") {
# Prepare data
violin_data <- as.data.frame(normalized_counts)
# Remove 'gene' column if it exists
if ("gene" %in% colnames(violin_data)) {
violin_data$gene <- NULL
}
# Proceed to reshape data
violin_data <- violin_data %>%
pivot_longer(
cols = everything(),
names_to = "sample",
values_to = "normalized_counts"
)
# violin_data$group <- selected_samples[[params$group_column]][match(violin_data$sample, selected_samples[[params$sample_column]])]
violin_data$group <- factor(violin_data$group)
violin_data$group <- factor(samples$groupName)
violin_data$sample <- factor(violin_data$sample,
levels = violin_data %>%
distinct(sample, group) %>%
arrange(group, sample) %>%
pull(sample))
violin_data$normalized_counts <- as.numeric(violin_data$normalized_counts)
violin_data <- violin_data %>% filter(normalized_counts > 0)
# Plot
violin_plot <- ggplot(violin_data, aes(x = sample, y = normalized_counts, fill = group)) +
geom_violin(scale = "width", trim = TRUE, alpha = 0.7) +
geom_boxplot(width = 0.1, outlier.shape = 16, outlier.size = 1, alpha = 0.5) +
scale_y_log10() +
scale_fill_manual(values = group_colors) +
theme_bw() +
labs(
title = title,
x = xlab,
y = ylab,
fill = "Group"
) +
theme(
axis.text.x = element_text(angle = 90, hjust = 1),
legend.position = "top"
) + coord_flip()
return(violin_plot)
}
make_pca_plots <- function(normalized_counts,
selected_samples,
title = "PCA Plot of Normalized Counts") {
# Convert input to data frame and set rownames
normalized_counts <- normalized_counts %>%
as.data.frame() %>%
{
if ("gene" %in% colnames(.)) {
column_to_rownames(., var = "gene")
} else {
.
}
# Remove genes with zero variance
normalized_counts <- normalized_counts[apply(normalized_counts, 1, var) > 0, ]
# Perform PCA
pca <- prcomp(t(normalized_counts), center = TRUE, scale. = TRUE)
pca_data <- as.data.frame(pca$x)
# % Variance explained
pca_var <- pca$sdev^2
pca_var_exp <- round(100 * pca_var / sum(pca_var), 1)
# Annotate PCA metadata
pca_data$sample <- rownames(pca_data)
pca_data$group <- selected_samples[[params$group_column]][match(pca_data$sample, selected_samples[[params$sample_column]])]
pca_data$group <- factor(pca_data$group)
if (isTRUE(params$usebatch)) {
pca_data$batch <- selected_samples[[params$batch_column]][match(pca_data$sample, selected_samples[[params$sample_column]])]
pca_data$batch <- factor(pca_data$batch)
} else {
pca_data$batch <- NA
}
# Hover text for 2D
pca_data$hover2d <- paste0(
"Sample: ", pca_data$sample,
"<br>Group: ", pca_data$group,
"<br>Batch: ", pca_data$batch,
"<br>PC1: ", round(pca_data$PC1, 2),
"<br>PC2: ", round(pca_data$PC2, 2)
)
# Hover text for 3D
pca_data$hover3d <- paste0(
"Sample: ", pca_data$sample,
"<br>Group: ", pca_data$group,
"<br>Batch: ", pca_data$batch,
"<br>PC1: ", round(pca_data$PC1, 2),
"<br>PC2: ", round(pca_data$PC2, 2),
"<br>PC3: ", round(pca_data$PC3, 2)
)
# 2D PCA plot
pca2d <- plot_ly(
data = pca_data,
x = ~PC1,
y = ~PC2,
color = ~group,
text = ~hover2d,
type = 'scatter',
mode = 'markers',
symbol = if (isTRUE(params$usebatch)) ~batch else I("circle"),
marker = list(size = 10),
hoverinfo = "text"
) %>%
layout(
title = title,
xaxis = list(title = paste0("PC1 (", pca_var_exp[1], "%)")),
yaxis = list(title = paste0("PC2 (", pca_var_exp[2], "%)")),
legend = list(
orientation = "v",   # vertical legend
x = 1.05,            # move to right outside plot
y = 1,
font = list(size = 10),
itemsizing = 'constant'
),
margin = list(r = 150) # add room on right for legend
)
# 3D PCA plot
pca3d <- plot_ly(
data = pca_data,
x = ~PC1,
y = ~PC2,
z = ~PC3,
color = ~group,
text = ~hover3d,
type = "scatter3d",
mode = "markers",
symbol = if (isTRUE(params$usebatch)) ~batch else I("circle"),
marker = list(size = 5),
hoverinfo = "text"
) %>%
layout(
title = title,
scene = list(
xaxis = list(title = paste0("PC1 (", pca_var_exp[1], "%)")),
yaxis = list(title = paste0("PC2 (", pca_var_exp[2], "%)")),
zaxis = list(title = paste0("PC3 (", pca_var_exp[3], "%)"))
),
legend = list(
orientation = "v",   # vertical layout
x = 1.05,            # push legend to the right
y = 1,
font = list(size = 10),
itemsizing = 'constant'
),
margin = list(r = 150)  # increase right margin
)
return(list(
pca2d = pca2d,
pca3d = pca3d
))
}
plot_all_violin_by_group <- function(expr_df, samples_df, xlab="", ylab="",title = "Gene expression distribution") {
library(ggplot2)
library(reshape2)
# Melt expression matrix into long format
df_long <- melt(expr_df, id.vars = "gene",
variable.name = "sampleName", value.name = "expression")
# Merge with sample group info
df_long <- merge(df_long, samples_df, by = "sampleName")
# Create horizontal violin plot
p <- ggplot(df_long, aes(x = sampleName, y = expression, fill = groupName)) +
geom_violin(scale = "width", trim = FALSE) +
coord_flip() +
theme_bw(base_size = 14) +
theme(
axis.text.y = element_text(size = 10),
axis.text.x = element_text(size = 12),
axis.title.x = element_text(size = 14),
axis.title.y = element_blank(),
legend.title = element_blank(),
plot.title = element_text(hjust = 0.5, size = 16)
) +
labs(
title = title,
x = xlab,
y = ylab
)
return(p)
}
#| code-fold: true
#| code-summary: "📊 Limma Analysis"
#| message: true
#| warning: false
#| echo: false
group_design <- model.matrix(~ 0 + samples[[params$group_column]])
colnames(group_design) <- levels(samples[[params$group_column]])
if (isTRUE(params$usebatch)) {
# Model matrix for batch
batch_design <- model.matrix(~ 0 + samples[[params$batch_column]])
colnames(batch_design) <- levels(samples[[params$batch_column]])
# Combine batch and group designs
raw_design <- cbind(batch_design, group_design)
# Compute QR decomposition to get full-rank column indices
qr_decomp <- qr(raw_design)
rank_cols <- qr_decomp$pivot[1:qr_decomp$rank]
full_rank_colnames <- colnames(raw_design)[rank_cols]
# Subset the final design
limma_design <- raw_design[, full_rank_colnames, drop = FALSE]
} else {
# directly use group_design
limma_design <- group_design
}
if (isTRUE(params$useERCC)) {
print(glue::glue("✅ ERCC standard curve slope - based normalization enabled."))
dims <- dim(pseudo_log2_normalized_counts)
# get batch corrected counts
if (isTRUE(params$usebatch)){
pseudo_log2_normalized_counts_batch_corrected <- limma::removeBatchEffect(
pseudo_log2_normalized_counts,
batch = samples[[params$batch_column]],
design = model.matrix(~ 0 + samples[[params$group_column]])
)
pseudo_log2_normalized_counts_batch_corrected <- as.data.frame(pseudo_log2_normalized_counts_batch_corrected)
}
} else {
print(glue::glue("✅ Using Limma-voom for normalization."))
# 1. Create DGEList
dge <- DGEList(counts = ready_for_deg_raw_counts)
group <- samples[[params$group_column]]
dge$samples$group <- group
if (isTRUE(params$usebatch)) {
batch <- samples[[params$batch_column]]
dge$samples$batch <- batch
}
# 2. Filtering
keep <- filterByExpr(dge, group = group)
dge <- dge[keep,, keep.lib.sizes = FALSE]
dge <- calcNormFactors(dge)
# 3. Design matrix with optional batch covariate
# using limma_design
# 4. Voom
v <- voom(dge, limma_design, plot = TRUE)
# 5. Save log2 values
log2_raw_cpm <- as.data.frame(cpm(dge, log = TRUE, prior.count = 1))
log2_normalized_counts_limma <- as.data.frame(v$E)
dims <- dim(log2_normalized_counts_limma)
if (isTRUE(params$usebatch)){
log2_normalized_counts_limma_batch_corrected <- limma::removeBatchEffect(
log2_normalized_counts_limma,
batch = samples[[params$batch_column]],
design = model.matrix(~ 0 + samples[[params$group_column]])
)
log2_normalized_counts_limma_batch_corrected <- as.data.frame(log2_normalized_counts_limma_batch_corrected)
}
# 1. Create DGEList
dge <- DGEList(counts = ready_for_deg_raw_counts)
group <- samples[[params$group_column]]
dge$samples$group <- group
batch <- samples[[params$batch_column]]
dge$samples$batch <- batch
# 2. Filtering
keep <- filterByExpr(dge, group = group)
dge <- dge[keep,, keep.lib.sizes = FALSE]
dge <- calcNormFactors(dge)
limma_design
raw_design
group_design
batch_design
samples
limma_design <- model.matrix(~ 0 + batch + groupName, data = samples)
limma_design
#| code-fold: true
#| code-summary: "📊 Limma Analysis"
#| message: true
#| warning: false
#| echo: false
group_design <- model.matrix(~ 0 + samples[[params$group_column]])
colnames(group_design) <- levels(samples[[params$group_column]])
if (isTRUE(params$usebatch)) {
# Convert to factors
samples$batch <- factor(samples$batch)
samples$groupName <- factor(samples$groupName)
# Create a design matrix including both batch and group
limma_design <- model.matrix(~ 0 + batch + groupName, data = samples)
# Optional: cleaner column names
colnames(limma_design) <- make.names(colnames(limma_design))
# Sanity check
stopifnot(ncol(filtered_counts) == nrow(limma_design))
} else {
# directly use group_design
limma_design <- group_design
}
if (isTRUE(params$useERCC)) {
print(glue::glue("✅ ERCC standard curve slope - based normalization enabled."))
dims <- dim(pseudo_log2_normalized_counts)
# get batch corrected counts
if (isTRUE(params$usebatch)){
pseudo_log2_normalized_counts_batch_corrected <- limma::removeBatchEffect(
pseudo_log2_normalized_counts,
batch = samples[[params$batch_column]],
design = model.matrix(~ 0 + samples[[params$group_column]])
)
pseudo_log2_normalized_counts_batch_corrected <- as.data.frame(pseudo_log2_normalized_counts_batch_corrected)
}
} else {
print(glue::glue("✅ Using Limma-voom for normalization."))
# 1. Create DGEList
dge <- DGEList(counts = ready_for_deg_raw_counts)
group <- samples[[params$group_column]]
dge$samples$group <- group
if (isTRUE(params$usebatch)) {
batch <- samples[[params$batch_column]]
dge$samples$batch <- batch
}
# 2. Filtering
keep <- filterByExpr(dge, group = group)
dge <- dge[keep,, keep.lib.sizes = FALSE]
dge <- calcNormFactors(dge)
# 3. Design matrix with optional batch covariate
# using limma_design
# 4. Voom
v <- voom(dge, limma_design, plot = TRUE)
# 5. Save log2 values
log2_raw_cpm <- as.data.frame(cpm(dge, log = TRUE, prior.count = 1))
log2_normalized_counts_limma <- as.data.frame(v$E)
dims <- dim(log2_normalized_counts_limma)
if (isTRUE(params$usebatch)){
log2_normalized_counts_limma_batch_corrected <- limma::removeBatchEffect(
log2_normalized_counts_limma,
batch = samples[[params$batch_column]],
design = model.matrix(~ 0 + samples[[params$group_column]])
)
log2_normalized_counts_limma_batch_corrected <- as.data.frame(log2_normalized_counts_limma_batch_corrected)
}
renv::update()
.rs.restartR()
renv::snapshot()
#| code-fold: true
#| code-summary: "📦 Load Required Packages"
suppressPackageStartupMessages({
library(limma)
library(edgeR)
library(DESeq2)
library(tibble)
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(plotly)
library(EnhancedVolcano)
library(knitr)
library(kableExtra)
library(ggplotify)
library(ggpubr)
library(ggrepel)
library(openxlsx)
library(glue)
library(DT)
library(ComplexHeatmap)
library(clusterProfiler)
library(org.Hs.eg.db)
library(org.Mm.eg.db)
library(msigdbr)
library(UpSetR)
library(ggplot2)
library(plotly)
library(openxlsx)
library(yaml)
library(fs)
library(VennDiagram)
library(grid)
library(sva)
library(UpSetR)
})
exit_gracefully <- function() {
message("Exiting early: Debugging script intentionally halted.")
knitr::knit_exit()
}
# Paths
output_base <- params$outdir
counts_dir <- file.path(output_base, "counts")
edger_deg_dir <- file.path(output_base, "edgeR_deg")
deseq2_deg_dir <- file.path(output_base, "DESeq2_deg")
limma_deg_dir <- file.path(output_base, "limma_deg")
# gsea_dir <- file.path(output_base, "gsea")
# Create folders
fs::dir_create(c(output_base,counts_dir, edger_deg_dir, deseq2_deg_dir,limma_deg_dir))
# write out params
# Convert Quarto parameters (params) to a named list
yaml_params <- as.list(params)
# Write to YAML file
yaml::write_yaml(yaml_params, file.path(output_base, "params_received.yaml"))
renv::activate()
usethis::create_project(path = ".", open = FALSE)
library(usethis)
install.packages("usethis")
usethis::create_project(path = ".", open = FALSE)
here::dr_here()
install.packages('here')
here::dr_here()
usethis::use_rstudio()
renv::init()
renv::dependencies("diffex")
renv::restore()
renv::snapshot()
renv::status()
renv::activate()
renv::restore()
deps <- renv::dependencies("diffex")$Package
deps
renv::install(unique(deps))
renv::settings$bioconductor.version("3.20")
install.packages("BiocManager")
renv::install(unique(deps), repos = BiocManager::repositories())
renv::snapshot()
renv::activate(".")
getwd()
renv::activate(".")
deps <- renv::dependencies("diffex")$Package
deps
renv::install(unique(deps), repos = BiocManager::repositories())
renv::snapshot()
